{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFiL5gB0i88nCEa3TSb9l7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/immin0241/school_projects/blob/master/3_1_ai/wip_ai_jobs_wage_expectation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf0PlaXZMf3P",
        "outputId": "aef782d9-c299-44b8-c8ce-6d51f58e973d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터 수: 577개, 테스트 데이터 수: 145개\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 89105.2969 - mae: 89105.2969 - val_loss: 88673.5781 - val_mae: 88673.5781\n",
            "Epoch 2/200\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 86264.7344 - mae: 86264.7344 - val_loss: 88639.9141 - val_mae: 88639.9141\n",
            "Epoch 3/200\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 83414.6406 - mae: 83414.6406 - val_loss: 88441.3906 - val_mae: 88441.3906\n",
            "Epoch 4/200\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 89592.2891 - mae: 89592.2891 - val_loss: 87711.5781 - val_mae: 87711.5781\n",
            "Epoch 5/200\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 85169.0859 - mae: 85169.0859 - val_loss: 85804.7734 - val_mae: 85804.7734\n",
            "Epoch 6/200\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 82521.7656 - mae: 82521.7656 - val_loss: 81732.0547 - val_mae: 81732.0547\n",
            "Epoch 7/200\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 80607.3281 - mae: 80607.3281 - val_loss: 74246.9062 - val_mae: 74246.9062\n",
            "Epoch 8/200\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 69340.7500 - mae: 69340.7500 - val_loss: 61727.3008 - val_mae: 61727.3008\n",
            "Epoch 9/200\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 56160.8047 - mae: 56160.8047 - val_loss: 43942.1328 - val_mae: 43942.1328\n",
            "Epoch 10/200\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 37064.8438 - mae: 37064.8438 - val_loss: 33701.9453 - val_mae: 33701.9453\n",
            "Epoch 11/200\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 26496.7168 - mae: 26496.7168 - val_loss: 30547.7520 - val_mae: 30547.7520\n",
            "Epoch 12/200\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28351.0020 - mae: 28351.0020 - val_loss: 29041.0391 - val_mae: 29041.0391\n",
            "Epoch 13/200\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 26690.3594 - mae: 26690.3594 - val_loss: 28053.7852 - val_mae: 28053.7852\n",
            "Epoch 14/200\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 26490.1641 - mae: 26490.1641 - val_loss: 27314.9102 - val_mae: 27314.9102\n",
            "Epoch 15/200\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24712.0918 - mae: 24712.0918 - val_loss: 26630.9316 - val_mae: 26630.9316\n",
            "Epoch 16/200\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25283.5293 - mae: 25283.5293 - val_loss: 25876.9316 - val_mae: 25876.9316\n",
            "Epoch 17/200\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 24583.9199 - mae: 24583.9199 - val_loss: 25162.8477 - val_mae: 25162.8477\n",
            "Epoch 18/200\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 22171.5742 - mae: 22171.5742 - val_loss: 24489.5762 - val_mae: 24489.5762\n",
            "Epoch 19/200\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21792.4531 - mae: 21792.4531 - val_loss: 23799.2988 - val_mae: 23799.2988\n",
            "Epoch 20/200\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23494.1426 - mae: 23494.1426 - val_loss: 23228.8809 - val_mae: 23228.8809\n",
            "Epoch 21/200\n",
            "\u001b[1m 1/29\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 19990.9609 - mae: 19990.9609"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "df = pd.read_csv('/content/ai_job_dataset.csv')\n",
        "\n",
        "korea_df = df[df['company_location'] == 'South Korea'].copy()\n",
        "\n",
        "features = ['required_skills', 'experience_level', 'years_experience']\n",
        "target = 'salary_usd'\n",
        "\n",
        "X = korea_df[features]\n",
        "y = korea_df[target]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(f\"훈련 데이터 수: {len(X_train)}개, 테스트 데이터 수: {len(X_test)}개\")\n",
        "\n",
        "text_transformer = CountVectorizer(tokenizer=lambda x: [i.strip() for i in x.split(',')], max_features=300, binary=True)\n",
        "\n",
        "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "numeric_transformer = MinMaxScaler()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('text', text_transformer, 'required_skills'),\n",
        "        ('cat', categorical_transformer, ['experience_level']),\n",
        "        ('num', numeric_transformer, ['years_experience'])    ],\n",
        "    remainder='passthrough' )\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['mae'])\n",
        "\n",
        "\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('regressor', model)])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "history = pipeline.fit(X_train, y_train,\n",
        "                       regressor__epochs=200,\n",
        "                       regressor__batch_size=16,\n",
        "                       regressor__validation_split=0.2,\n",
        "                       regressor__callbacks=[early_stopping],\n",
        "                       regressor__verbose=1)\n",
        "\n",
        "# Preprocess X_test before evaluating the model\n",
        "X_test_processed = pipeline.named_steps['preprocessor'].transform(X_test)\n",
        "\n",
        "loss, mae = model.evaluate(X_test_processed, y_test, verbose=0)\n",
        "print(f\"\\n테스트 데이터에 대한 최종 Mean Absolute Error (MAE): ${mae:,.2f}\")\n",
        "print(f\"-> 모델의 연봉 예측치가 실제값과 평균적으로 ${mae:,.2f} 정도 차이남을 의미합니다.\")\n",
        "\n",
        "\n",
        "predictions = pipeline.predict(X_test)\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    'Actual Salary': y_test.values.flatten(),\n",
        "    'Predicted Salary': predictions.flatten()\n",
        "})\n",
        "results_df['Difference'] = results_df['Actual Salary'] - results_df['Predicted Salary']\n",
        "\n",
        "print(\"\\n--- 실제 연봉과 예측 연봉 비교 (상위 5개) ---\")\n",
        "print(results_df.head())"
      ]
    }
  ]
}