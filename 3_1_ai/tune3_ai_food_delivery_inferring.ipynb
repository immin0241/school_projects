{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a7f148d-cb61-4d36-b077-509f96e0b772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 00:36:21.621042: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-11 00:36:21.675513: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749569781.706570   20772 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749569781.716500   20772 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749569781.764497   20772 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749569781.764542   20772 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749569781.764544   20772 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749569781.764545   20772 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-11 00:36:21.780124: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.19.0\n",
      "GPU is available\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "   import tensorflow as tf\n",
    "   print(f\"TF version: {tf.__version__}\")\n",
    "   gpus = tf.config.list_physical_devices('GPU')\n",
    "   if gpus:\n",
    "       print(\"GPU is available\")\n",
    "       print(\"Num GPUs Available: \", len(gpus))\n",
    "   else:\n",
    "       print(\"No GPUs available in your system.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "242add55-5be7-4cce-b197-74ef5c255923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 수: 706개, 테스트 데이터 수: 177개\n",
      "Epoch 1/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - loss: 57.5885 - mae: 57.5885 - val_loss: 57.4229 - val_mae: 57.4229\n",
      "Epoch 2/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 56.0050 - mae: 56.0050 - val_loss: 57.3129 - val_mae: 57.3129\n",
      "Epoch 3/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 56.0626 - mae: 56.0626 - val_loss: 57.2017 - val_mae: 57.2017\n",
      "Epoch 4/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 55.6174 - mae: 55.6174 - val_loss: 57.0902 - val_mae: 57.0902\n",
      "Epoch 5/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 56.3882 - mae: 56.3882 - val_loss: 56.9776 - val_mae: 56.9776\n",
      "Epoch 6/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 54.9879 - mae: 54.9879 - val_loss: 56.8629 - val_mae: 56.8629\n",
      "Epoch 7/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 54.8258 - mae: 54.8258 - val_loss: 56.7461 - val_mae: 56.7461\n",
      "Epoch 8/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 55.9441 - mae: 55.9441 - val_loss: 56.6261 - val_mae: 56.6261\n",
      "Epoch 9/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 56.4879 - mae: 56.4879 - val_loss: 56.5040 - val_mae: 56.5040\n",
      "Epoch 10/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 54.9645 - mae: 54.9645 - val_loss: 56.3793 - val_mae: 56.3793\n",
      "Epoch 11/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 55.0931 - mae: 55.0931 - val_loss: 56.2510 - val_mae: 56.2510\n",
      "Epoch 12/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 55.3454 - mae: 55.3454 - val_loss: 56.1190 - val_mae: 56.1190\n",
      "Epoch 13/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 55.2586 - mae: 55.2586 - val_loss: 55.9822 - val_mae: 55.9822\n",
      "Epoch 14/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 55.7402 - mae: 55.7402 - val_loss: 55.8418 - val_mae: 55.8418\n",
      "Epoch 15/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 55.4685 - mae: 55.4685 - val_loss: 55.6955 - val_mae: 55.6955\n",
      "Epoch 16/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 55.5727 - mae: 55.5727 - val_loss: 55.5436 - val_mae: 55.5436\n",
      "Epoch 17/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 55.9289 - mae: 55.9289 - val_loss: 55.3880 - val_mae: 55.3880\n",
      "Epoch 18/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 55.2921 - mae: 55.2921 - val_loss: 55.2267 - val_mae: 55.2267\n",
      "Epoch 19/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 54.7371 - mae: 54.7371 - val_loss: 55.0593 - val_mae: 55.0593\n",
      "Epoch 20/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 53.6387 - mae: 53.6387 - val_loss: 54.8845 - val_mae: 54.8845\n",
      "Epoch 21/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 54.4960 - mae: 54.4960 - val_loss: 54.7042 - val_mae: 54.7042\n",
      "Epoch 22/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 54.0901 - mae: 54.0901 - val_loss: 54.5150 - val_mae: 54.5150\n",
      "Epoch 23/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 54.7032 - mae: 54.7032 - val_loss: 54.3173 - val_mae: 54.3173\n",
      "Epoch 24/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 53.7921 - mae: 53.7921 - val_loss: 54.1116 - val_mae: 54.1116\n",
      "Epoch 25/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 53.7581 - mae: 53.7581 - val_loss: 53.8969 - val_mae: 53.8969\n",
      "Epoch 26/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 54.2100 - mae: 54.2100 - val_loss: 53.6737 - val_mae: 53.6737\n",
      "Epoch 27/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 52.1382 - mae: 52.1382 - val_loss: 53.4402 - val_mae: 53.4402\n",
      "Epoch 28/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 52.9739 - mae: 52.9739 - val_loss: 53.1981 - val_mae: 53.1981\n",
      "Epoch 29/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 51.9884 - mae: 51.9884 - val_loss: 52.9426 - val_mae: 52.9426\n",
      "Epoch 30/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 52.5178 - mae: 52.5178 - val_loss: 52.6776 - val_mae: 52.6776\n",
      "Epoch 31/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 51.8033 - mae: 51.8033 - val_loss: 52.3996 - val_mae: 52.3996\n",
      "Epoch 32/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 52.5178 - mae: 52.5178 - val_loss: 52.1110 - val_mae: 52.1110\n",
      "Epoch 33/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 51.7764 - mae: 51.7764 - val_loss: 51.8082 - val_mae: 51.8082\n",
      "Epoch 34/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 50.3120 - mae: 50.3120 - val_loss: 51.4904 - val_mae: 51.4904\n",
      "Epoch 35/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 50.6970 - mae: 50.6970 - val_loss: 51.1565 - val_mae: 51.1565\n",
      "Epoch 36/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 51.0540 - mae: 51.0540 - val_loss: 50.8122 - val_mae: 50.8122\n",
      "Epoch 37/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 50.2868 - mae: 50.2868 - val_loss: 50.4490 - val_mae: 50.4490\n",
      "Epoch 38/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 49.8580 - mae: 49.8580 - val_loss: 50.0724 - val_mae: 50.0724\n",
      "Epoch 39/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 48.8070 - mae: 48.8070 - val_loss: 49.6770 - val_mae: 49.6770\n",
      "Epoch 40/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 50.2566 - mae: 50.2566 - val_loss: 49.2705 - val_mae: 49.2705\n",
      "Epoch 41/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 48.5149 - mae: 48.5149 - val_loss: 48.8445 - val_mae: 48.8445\n",
      "Epoch 42/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 48.4243 - mae: 48.4243 - val_loss: 48.3993 - val_mae: 48.3993\n",
      "Epoch 43/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 48.3561 - mae: 48.3561 - val_loss: 47.9320 - val_mae: 47.9320\n",
      "Epoch 44/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 47.8298 - mae: 47.8298 - val_loss: 47.4418 - val_mae: 47.4418\n",
      "Epoch 45/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 45.8469 - mae: 45.8469 - val_loss: 46.9337 - val_mae: 46.9337\n",
      "Epoch 46/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 47.0224 - mae: 47.0224 - val_loss: 46.4047 - val_mae: 46.4047\n",
      "Epoch 47/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 45.0872 - mae: 45.0872 - val_loss: 45.8537 - val_mae: 45.8537\n",
      "Epoch 48/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 44.9789 - mae: 44.9789 - val_loss: 45.2821 - val_mae: 45.2821\n",
      "Epoch 49/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 44.0840 - mae: 44.0840 - val_loss: 44.6835 - val_mae: 44.6835\n",
      "Epoch 50/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 43.7104 - mae: 43.7104 - val_loss: 44.0635 - val_mae: 44.0635\n",
      "Epoch 51/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 43.2573 - mae: 43.2573 - val_loss: 43.4180 - val_mae: 43.4180\n",
      "Epoch 52/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 42.3662 - mae: 42.3662 - val_loss: 42.7432 - val_mae: 42.7432\n",
      "Epoch 53/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 42.2561 - mae: 42.2561 - val_loss: 42.0362 - val_mae: 42.0362\n",
      "Epoch 54/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 41.1048 - mae: 41.1048 - val_loss: 41.3100 - val_mae: 41.3100\n",
      "Epoch 55/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 40.0004 - mae: 40.0004 - val_loss: 40.5528 - val_mae: 40.5528\n",
      "Epoch 56/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 40.3684 - mae: 40.3684 - val_loss: 39.7630 - val_mae: 39.7630\n",
      "Epoch 57/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 39.0519 - mae: 39.0519 - val_loss: 38.9545 - val_mae: 38.9545\n",
      "Epoch 58/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 38.0203 - mae: 38.0203 - val_loss: 38.1207 - val_mae: 38.1207\n",
      "Epoch 59/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 36.6968 - mae: 36.6968 - val_loss: 37.2586 - val_mae: 37.2586\n",
      "Epoch 60/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 36.7950 - mae: 36.7950 - val_loss: 36.3719 - val_mae: 36.3719\n",
      "Epoch 61/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 37.2974 - mae: 37.2974 - val_loss: 35.4618 - val_mae: 35.4618\n",
      "Epoch 62/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 34.3499 - mae: 34.3499 - val_loss: 34.5312 - val_mae: 34.5312\n",
      "Epoch 63/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 35.9617 - mae: 35.9617 - val_loss: 33.5921 - val_mae: 33.5921\n",
      "Epoch 64/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 33.3516 - mae: 33.3516 - val_loss: 32.6587 - val_mae: 32.6587\n",
      "Epoch 65/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.0169 - mae: 32.0169 - val_loss: 31.7334 - val_mae: 31.7334\n",
      "Epoch 66/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.8724 - mae: 31.8724 - val_loss: 30.8004 - val_mae: 30.8004\n",
      "Epoch 67/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.0888 - mae: 30.0888 - val_loss: 29.8359 - val_mae: 29.8359\n",
      "Epoch 68/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.1414 - mae: 30.1414 - val_loss: 28.8902 - val_mae: 28.8902\n",
      "Epoch 69/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.8128 - mae: 28.8128 - val_loss: 27.9607 - val_mae: 27.9607\n",
      "Epoch 70/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.3184 - mae: 27.3184 - val_loss: 27.0242 - val_mae: 27.0242\n",
      "Epoch 71/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.8018 - mae: 27.8018 - val_loss: 26.0763 - val_mae: 26.0763\n",
      "Epoch 72/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.5276 - mae: 24.5276 - val_loss: 25.1646 - val_mae: 25.1646\n",
      "Epoch 73/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.8653 - mae: 25.8653 - val_loss: 24.2668 - val_mae: 24.2668\n",
      "Epoch 74/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.7165 - mae: 23.7165 - val_loss: 23.4343 - val_mae: 23.4343\n",
      "Epoch 75/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.0954 - mae: 24.0954 - val_loss: 22.6256 - val_mae: 22.6256\n",
      "Epoch 76/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.2446 - mae: 23.2446 - val_loss: 21.8386 - val_mae: 21.8386\n",
      "Epoch 77/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 22.1413 - mae: 22.1413 - val_loss: 21.0876 - val_mae: 21.0876\n",
      "Epoch 78/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 19.5721 - mae: 19.5721 - val_loss: 20.3757 - val_mae: 20.3757\n",
      "Epoch 79/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 20.2791 - mae: 20.2791 - val_loss: 19.7053 - val_mae: 19.7053\n",
      "Epoch 80/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 19.7120 - mae: 19.7120 - val_loss: 19.0610 - val_mae: 19.0610\n",
      "Epoch 81/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 18.5246 - mae: 18.5246 - val_loss: 18.4896 - val_mae: 18.4896\n",
      "Epoch 82/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 19.0085 - mae: 19.0085 - val_loss: 17.9175 - val_mae: 17.9175\n",
      "Epoch 83/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 18.4765 - mae: 18.4765 - val_loss: 17.3768 - val_mae: 17.3768\n",
      "Epoch 84/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 16.1049 - mae: 16.1049 - val_loss: 16.8731 - val_mae: 16.8731\n",
      "Epoch 85/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 17.2150 - mae: 17.2150 - val_loss: 16.3934 - val_mae: 16.3934\n",
      "Epoch 86/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 15.8769 - mae: 15.8769 - val_loss: 15.9686 - val_mae: 15.9686\n",
      "Epoch 87/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 15.6163 - mae: 15.6163 - val_loss: 15.5687 - val_mae: 15.5687\n",
      "Epoch 88/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 16.5555 - mae: 16.5555 - val_loss: 15.2026 - val_mae: 15.2026\n",
      "Epoch 89/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 15.1695 - mae: 15.1695 - val_loss: 14.9033 - val_mae: 14.9033\n",
      "Epoch 90/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 13.9237 - mae: 13.9237 - val_loss: 14.6396 - val_mae: 14.6396\n",
      "Epoch 91/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 15.1450 - mae: 15.1450 - val_loss: 14.4157 - val_mae: 14.4157\n",
      "Epoch 92/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 15.1850 - mae: 15.1850 - val_loss: 14.2094 - val_mae: 14.2094\n",
      "Epoch 93/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 14.5895 - mae: 14.5895 - val_loss: 14.0165 - val_mae: 14.0165\n",
      "Epoch 94/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 15.6307 - mae: 15.6307 - val_loss: 13.8341 - val_mae: 13.8341\n",
      "Epoch 95/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 14.5067 - mae: 14.5067 - val_loss: 13.6652 - val_mae: 13.6652\n",
      "Epoch 96/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 14.2213 - mae: 14.2213 - val_loss: 13.4941 - val_mae: 13.4941\n",
      "Epoch 97/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 14.4571 - mae: 14.4571 - val_loss: 13.3235 - val_mae: 13.3235\n",
      "Epoch 98/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 14.0110 - mae: 14.0110 - val_loss: 13.1351 - val_mae: 13.1351\n",
      "Epoch 99/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 14.1223 - mae: 14.1223 - val_loss: 12.9749 - val_mae: 12.9749\n",
      "Epoch 100/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 14.1208 - mae: 14.1208 - val_loss: 12.8332 - val_mae: 12.8332\n",
      "Epoch 101/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 13.8816 - mae: 13.8816 - val_loss: 12.6907 - val_mae: 12.6907\n",
      "Epoch 102/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 14.0624 - mae: 14.0624 - val_loss: 12.5521 - val_mae: 12.5521\n",
      "Epoch 103/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 13.7749 - mae: 13.7749 - val_loss: 12.4035 - val_mae: 12.4035\n",
      "Epoch 104/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 13.4484 - mae: 13.4484 - val_loss: 12.2512 - val_mae: 12.2512\n",
      "Epoch 105/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 13.0055 - mae: 13.0055 - val_loss: 12.1128 - val_mae: 12.1128\n",
      "Epoch 106/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 13.5758 - mae: 13.5758 - val_loss: 11.9750 - val_mae: 11.9750\n",
      "Epoch 107/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 13.4747 - mae: 13.4747 - val_loss: 11.8456 - val_mae: 11.8456\n",
      "Epoch 108/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 13.7971 - mae: 13.7971 - val_loss: 11.7302 - val_mae: 11.7302\n",
      "Epoch 109/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 13.1926 - mae: 13.1926 - val_loss: 11.6095 - val_mae: 11.6095\n",
      "Epoch 110/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 13.6317 - mae: 13.6317 - val_loss: 11.4929 - val_mae: 11.4929\n",
      "Epoch 111/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12.7437 - mae: 12.7437 - val_loss: 11.3740 - val_mae: 11.3740\n",
      "Epoch 112/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 13.2328 - mae: 13.2328 - val_loss: 11.2672 - val_mae: 11.2672\n",
      "Epoch 113/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12.8972 - mae: 12.8972 - val_loss: 11.1599 - val_mae: 11.1599\n",
      "Epoch 114/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12.6497 - mae: 12.6497 - val_loss: 11.0527 - val_mae: 11.0527\n",
      "Epoch 115/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12.7539 - mae: 12.7539 - val_loss: 10.9310 - val_mae: 10.9310\n",
      "Epoch 116/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 12.4691 - mae: 12.4691 - val_loss: 10.8358 - val_mae: 10.8358\n",
      "Epoch 117/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12.5392 - mae: 12.5392 - val_loss: 10.7520 - val_mae: 10.7520\n",
      "Epoch 118/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12.3436 - mae: 12.3436 - val_loss: 10.6739 - val_mae: 10.6739\n",
      "Epoch 119/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12.7484 - mae: 12.7484 - val_loss: 10.5832 - val_mae: 10.5832\n",
      "Epoch 120/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 13.1938 - mae: 13.1938 - val_loss: 10.4921 - val_mae: 10.4921\n",
      "Epoch 121/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.9321 - mae: 11.9321 - val_loss: 10.4211 - val_mae: 10.4211\n",
      "Epoch 122/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.5230 - mae: 11.5230 - val_loss: 10.3273 - val_mae: 10.3273\n",
      "Epoch 123/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.4518 - mae: 11.4518 - val_loss: 10.2261 - val_mae: 10.2261\n",
      "Epoch 124/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 12.6085 - mae: 12.6085 - val_loss: 10.1697 - val_mae: 10.1697\n",
      "Epoch 125/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.3915 - mae: 11.3915 - val_loss: 10.0996 - val_mae: 10.0996\n",
      "Epoch 126/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 12.2591 - mae: 12.2591 - val_loss: 10.0174 - val_mae: 10.0174\n",
      "Epoch 127/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.0791 - mae: 11.0791 - val_loss: 9.9622 - val_mae: 9.9622\n",
      "Epoch 128/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 12.2327 - mae: 12.2327 - val_loss: 9.8912 - val_mae: 9.8912\n",
      "Epoch 129/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 12.0198 - mae: 12.0198 - val_loss: 9.7735 - val_mae: 9.7735\n",
      "Epoch 130/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.3574 - mae: 11.3574 - val_loss: 9.7056 - val_mae: 9.7056\n",
      "Epoch 131/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.1316 - mae: 11.1316 - val_loss: 9.6316 - val_mae: 9.6316\n",
      "Epoch 132/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.6822 - mae: 11.6822 - val_loss: 9.5522 - val_mae: 9.5522\n",
      "Epoch 133/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.0614 - mae: 11.0614 - val_loss: 9.4751 - val_mae: 9.4751\n",
      "Epoch 134/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 12.1890 - mae: 12.1890 - val_loss: 9.4059 - val_mae: 9.4059\n",
      "Epoch 135/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.7451 - mae: 11.7451 - val_loss: 9.3420 - val_mae: 9.3420\n",
      "Epoch 136/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.8322 - mae: 10.8322 - val_loss: 9.2519 - val_mae: 9.2519\n",
      "Epoch 137/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.0911 - mae: 11.0911 - val_loss: 9.1758 - val_mae: 9.1758\n",
      "Epoch 138/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.7671 - mae: 11.7671 - val_loss: 9.1085 - val_mae: 9.1085\n",
      "Epoch 139/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.1954 - mae: 11.1954 - val_loss: 9.0436 - val_mae: 9.0436\n",
      "Epoch 140/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.0055 - mae: 11.0055 - val_loss: 8.9967 - val_mae: 8.9967\n",
      "Epoch 141/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.7713 - mae: 11.7713 - val_loss: 8.9276 - val_mae: 8.9276\n",
      "Epoch 142/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.5814 - mae: 11.5814 - val_loss: 8.8602 - val_mae: 8.8602\n",
      "Epoch 143/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.7993 - mae: 10.7993 - val_loss: 8.8277 - val_mae: 8.8277\n",
      "Epoch 144/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.3676 - mae: 11.3676 - val_loss: 8.7926 - val_mae: 8.7926\n",
      "Epoch 145/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.0394 - mae: 11.0394 - val_loss: 8.7429 - val_mae: 8.7429\n",
      "Epoch 146/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.3522 - mae: 11.3522 - val_loss: 8.6768 - val_mae: 8.6768\n",
      "Epoch 147/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.4031 - mae: 10.4031 - val_loss: 8.5816 - val_mae: 8.5816\n",
      "Epoch 148/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.0249 - mae: 11.0249 - val_loss: 8.5296 - val_mae: 8.5296\n",
      "Epoch 149/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.3963 - mae: 11.3963 - val_loss: 8.4768 - val_mae: 8.4768\n",
      "Epoch 150/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.8448 - mae: 10.8448 - val_loss: 8.4536 - val_mae: 8.4536\n",
      "Epoch 151/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.2205 - mae: 10.2205 - val_loss: 8.4723 - val_mae: 8.4723\n",
      "Epoch 152/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.3390 - mae: 11.3390 - val_loss: 8.4204 - val_mae: 8.4204\n",
      "Epoch 153/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.2636 - mae: 11.2636 - val_loss: 8.3699 - val_mae: 8.3699\n",
      "Epoch 154/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.9289 - mae: 10.9289 - val_loss: 8.3074 - val_mae: 8.3074\n",
      "Epoch 155/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 12.0597 - mae: 12.0597 - val_loss: 8.2188 - val_mae: 8.2188\n",
      "Epoch 156/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.5035 - mae: 10.5035 - val_loss: 8.1496 - val_mae: 8.1496\n",
      "Epoch 157/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.6201 - mae: 10.6201 - val_loss: 8.1314 - val_mae: 8.1314\n",
      "Epoch 158/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.6128 - mae: 10.6128 - val_loss: 8.1218 - val_mae: 8.1218\n",
      "Epoch 159/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.0337 - mae: 11.0337 - val_loss: 8.0752 - val_mae: 8.0752\n",
      "Epoch 160/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.0308 - mae: 11.0308 - val_loss: 8.0171 - val_mae: 8.0171\n",
      "Epoch 161/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.7347 - mae: 10.7347 - val_loss: 7.9841 - val_mae: 7.9841\n",
      "Epoch 162/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.4244 - mae: 10.4244 - val_loss: 7.9592 - val_mae: 7.9592\n",
      "Epoch 163/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.9474 - mae: 10.9474 - val_loss: 7.9271 - val_mae: 7.9271\n",
      "Epoch 164/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.3346 - mae: 11.3346 - val_loss: 7.8814 - val_mae: 7.8814\n",
      "Epoch 165/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.0420 - mae: 11.0420 - val_loss: 7.8252 - val_mae: 7.8252\n",
      "Epoch 166/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.3599 - mae: 11.3599 - val_loss: 7.7592 - val_mae: 7.7592\n",
      "Epoch 167/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.2038 - mae: 10.2038 - val_loss: 7.7274 - val_mae: 7.7274\n",
      "Epoch 168/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.0507 - mae: 10.0507 - val_loss: 7.6945 - val_mae: 7.6945\n",
      "Epoch 169/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.7719 - mae: 10.7719 - val_loss: 7.6820 - val_mae: 7.6820\n",
      "Epoch 170/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.7914 - mae: 10.7914 - val_loss: 7.6816 - val_mae: 7.6816\n",
      "Epoch 171/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.0449 - mae: 10.0449 - val_loss: 7.6604 - val_mae: 7.6604\n",
      "Epoch 172/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.8521 - mae: 10.8521 - val_loss: 7.6234 - val_mae: 7.6234\n",
      "Epoch 173/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.4444 - mae: 10.4444 - val_loss: 7.6107 - val_mae: 7.6107\n",
      "Epoch 174/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.3489 - mae: 11.3489 - val_loss: 7.6008 - val_mae: 7.6008\n",
      "Epoch 175/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.2842 - mae: 11.2842 - val_loss: 7.5546 - val_mae: 7.5546\n",
      "Epoch 176/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.8329 - mae: 10.8329 - val_loss: 7.5345 - val_mae: 7.5345\n",
      "Epoch 177/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.7757 - mae: 10.7757 - val_loss: 7.5271 - val_mae: 7.5271\n",
      "Epoch 178/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.3686 - mae: 10.3686 - val_loss: 7.4835 - val_mae: 7.4835\n",
      "Epoch 179/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.3650 - mae: 11.3650 - val_loss: 7.4589 - val_mae: 7.4589\n",
      "Epoch 180/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.6629 - mae: 10.6629 - val_loss: 7.4678 - val_mae: 7.4678\n",
      "Epoch 181/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.5017 - mae: 10.5017 - val_loss: 7.4792 - val_mae: 7.4792\n",
      "Epoch 182/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.1262 - mae: 10.1262 - val_loss: 7.4637 - val_mae: 7.4637\n",
      "Epoch 183/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.8374 - mae: 10.8374 - val_loss: 7.4592 - val_mae: 7.4592\n",
      "Epoch 184/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.2388 - mae: 10.2388 - val_loss: 7.4552 - val_mae: 7.4552\n",
      "Epoch 185/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.0487 - mae: 11.0487 - val_loss: 7.3897 - val_mae: 7.3897\n",
      "Epoch 186/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.6741 - mae: 10.6741 - val_loss: 7.3240 - val_mae: 7.3240\n",
      "Epoch 187/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.1698 - mae: 11.1698 - val_loss: 7.2583 - val_mae: 7.2583\n",
      "Epoch 188/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.4604 - mae: 10.4604 - val_loss: 7.2214 - val_mae: 7.2214\n",
      "Epoch 189/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.2941 - mae: 10.2941 - val_loss: 7.1862 - val_mae: 7.1862\n",
      "Epoch 190/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.9786 - mae: 10.9786 - val_loss: 7.1668 - val_mae: 7.1668\n",
      "Epoch 191/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.5776 - mae: 10.5776 - val_loss: 7.1688 - val_mae: 7.1688\n",
      "Epoch 192/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.3283 - mae: 11.3283 - val_loss: 7.2250 - val_mae: 7.2250\n",
      "Epoch 193/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.6360 - mae: 10.6360 - val_loss: 7.2446 - val_mae: 7.2446\n",
      "Epoch 194/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.3976 - mae: 10.3976 - val_loss: 7.2417 - val_mae: 7.2417\n",
      "Epoch 195/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.7396 - mae: 10.7396 - val_loss: 7.2339 - val_mae: 7.2339\n",
      "Epoch 196/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.3050 - mae: 10.3050 - val_loss: 7.2560 - val_mae: 7.2560\n",
      "Epoch 197/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.0462 - mae: 10.0462 - val_loss: 7.2815 - val_mae: 7.2815\n",
      "Epoch 198/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.9001 - mae: 10.9001 - val_loss: 7.3262 - val_mae: 7.3262\n",
      "Epoch 199/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.6391 - mae: 9.6391 - val_loss: 7.3342 - val_mae: 7.3342\n",
      "Epoch 200/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.9979 - mae: 10.9979 - val_loss: 7.2023 - val_mae: 7.2023\n",
      "Epoch 201/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.9562 - mae: 10.9562 - val_loss: 7.1073 - val_mae: 7.1073\n",
      "Epoch 202/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.6152 - mae: 10.6152 - val_loss: 7.0753 - val_mae: 7.0753\n",
      "Epoch 203/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.7164 - mae: 10.7164 - val_loss: 7.0900 - val_mae: 7.0900\n",
      "Epoch 204/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.7903 - mae: 10.7903 - val_loss: 7.0729 - val_mae: 7.0729\n",
      "Epoch 205/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.8799 - mae: 9.8799 - val_loss: 7.0363 - val_mae: 7.0363\n",
      "Epoch 206/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.7802 - mae: 10.7802 - val_loss: 7.0201 - val_mae: 7.0201\n",
      "Epoch 207/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.4375 - mae: 10.4375 - val_loss: 7.0511 - val_mae: 7.0511\n",
      "Epoch 208/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.2310 - mae: 11.2310 - val_loss: 7.0844 - val_mae: 7.0844\n",
      "Epoch 209/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.6022 - mae: 10.6022 - val_loss: 7.1357 - val_mae: 7.1357\n",
      "Epoch 210/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.1507 - mae: 10.1507 - val_loss: 7.1109 - val_mae: 7.1109\n",
      "Epoch 211/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.8313 - mae: 10.8313 - val_loss: 7.0586 - val_mae: 7.0586\n",
      "Epoch 212/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.6211 - mae: 10.6211 - val_loss: 6.9802 - val_mae: 6.9802\n",
      "Epoch 213/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.7733 - mae: 10.7733 - val_loss: 6.9377 - val_mae: 6.9377\n",
      "Epoch 214/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.7606 - mae: 10.7606 - val_loss: 6.8966 - val_mae: 6.8966\n",
      "Epoch 215/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.6280 - mae: 10.6280 - val_loss: 6.8964 - val_mae: 6.8964\n",
      "Epoch 216/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.1117 - mae: 10.1117 - val_loss: 6.8921 - val_mae: 6.8921\n",
      "Epoch 217/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.6552 - mae: 10.6552 - val_loss: 6.9204 - val_mae: 6.9204\n",
      "Epoch 218/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.2021 - mae: 10.2021 - val_loss: 6.9192 - val_mae: 6.9192\n",
      "Epoch 219/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.4618 - mae: 10.4618 - val_loss: 6.9416 - val_mae: 6.9416\n",
      "Epoch 220/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.4090 - mae: 10.4090 - val_loss: 6.9819 - val_mae: 6.9819\n",
      "Epoch 221/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.4217 - mae: 10.4217 - val_loss: 6.9780 - val_mae: 6.9780\n",
      "Epoch 222/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.2664 - mae: 10.2664 - val_loss: 6.9738 - val_mae: 6.9738\n",
      "Epoch 223/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.0252 - mae: 10.0252 - val_loss: 6.9481 - val_mae: 6.9481\n",
      "Epoch 224/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.4708 - mae: 9.4708 - val_loss: 6.9745 - val_mae: 6.9745\n",
      "Epoch 225/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.8602 - mae: 10.8602 - val_loss: 6.9700 - val_mae: 6.9700\n",
      "Epoch 226/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.1658 - mae: 11.1658 - val_loss: 6.9779 - val_mae: 6.9779\n",
      "Epoch 227/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.9489 - mae: 9.9489 - val_loss: 6.9112 - val_mae: 6.9112\n",
      "Epoch 228/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.7005 - mae: 9.7005 - val_loss: 6.8355 - val_mae: 6.8355\n",
      "Epoch 229/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.1221 - mae: 11.1221 - val_loss: 6.8584 - val_mae: 6.8584\n",
      "Epoch 230/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.5004 - mae: 10.5004 - val_loss: 6.8178 - val_mae: 6.8178\n",
      "Epoch 231/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.1626 - mae: 10.1626 - val_loss: 6.7940 - val_mae: 6.7940\n",
      "Epoch 232/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.3621 - mae: 10.3621 - val_loss: 6.8264 - val_mae: 6.8264\n",
      "Epoch 233/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.1416 - mae: 11.1416 - val_loss: 6.8517 - val_mae: 6.8517\n",
      "Epoch 234/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.9612 - mae: 9.9612 - val_loss: 6.9054 - val_mae: 6.9054\n",
      "Epoch 235/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.0715 - mae: 10.0715 - val_loss: 6.8626 - val_mae: 6.8626\n",
      "Epoch 236/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.0708 - mae: 10.0708 - val_loss: 6.9148 - val_mae: 6.9148\n",
      "Epoch 237/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.3860 - mae: 10.3860 - val_loss: 6.9126 - val_mae: 6.9126\n",
      "Epoch 238/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.9051 - mae: 9.9051 - val_loss: 6.8985 - val_mae: 6.8985\n",
      "Epoch 239/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.0763 - mae: 10.0763 - val_loss: 6.9701 - val_mae: 6.9701\n",
      "Epoch 240/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.5318 - mae: 10.5318 - val_loss: 6.9518 - val_mae: 6.9518\n",
      "Epoch 241/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.2727 - mae: 10.2727 - val_loss: 6.9091 - val_mae: 6.9091\n",
      "Epoch 242/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.7807 - mae: 10.7807 - val_loss: 6.8832 - val_mae: 6.8832\n",
      "Epoch 243/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.7171 - mae: 10.7171 - val_loss: 6.9123 - val_mae: 6.9123\n",
      "Epoch 244/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.0050 - mae: 10.0050 - val_loss: 6.9124 - val_mae: 6.9124\n",
      "Epoch 245/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.4711 - mae: 10.4711 - val_loss: 6.8573 - val_mae: 6.8573\n",
      "Epoch 246/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.5274 - mae: 10.5274 - val_loss: 6.8275 - val_mae: 6.8275\n",
      "Epoch 247/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.1848 - mae: 10.1848 - val_loss: 6.8111 - val_mae: 6.8111\n",
      "Epoch 248/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.8575 - mae: 10.8575 - val_loss: 6.7892 - val_mae: 6.7892\n",
      "Epoch 249/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.8781 - mae: 9.8781 - val_loss: 6.7262 - val_mae: 6.7262\n",
      "Epoch 250/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.6986 - mae: 10.6986 - val_loss: 6.7043 - val_mae: 6.7043\n",
      "Epoch 251/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.3882 - mae: 10.3882 - val_loss: 6.7028 - val_mae: 6.7028\n",
      "Epoch 252/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.6532 - mae: 10.6532 - val_loss: 6.7111 - val_mae: 6.7111\n",
      "Epoch 253/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.4721 - mae: 10.4721 - val_loss: 6.7708 - val_mae: 6.7708\n",
      "Epoch 254/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.4480 - mae: 9.4480 - val_loss: 6.7670 - val_mae: 6.7670\n",
      "Epoch 255/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.1565 - mae: 10.1565 - val_loss: 6.7846 - val_mae: 6.7846\n",
      "Epoch 256/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.3825 - mae: 10.3825 - val_loss: 6.7798 - val_mae: 6.7798\n",
      "Epoch 257/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.3083 - mae: 10.3083 - val_loss: 6.7198 - val_mae: 6.7198\n",
      "Epoch 258/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.3166 - mae: 10.3166 - val_loss: 6.7324 - val_mae: 6.7324\n",
      "Epoch 259/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.8286 - mae: 10.8286 - val_loss: 6.8200 - val_mae: 6.8200\n",
      "Epoch 260/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.2224 - mae: 10.2224 - val_loss: 6.9172 - val_mae: 6.9172\n",
      "Epoch 261/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.2021 - mae: 10.2021 - val_loss: 6.9747 - val_mae: 6.9747\n",
      "Epoch 262/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.5308 - mae: 10.5308 - val_loss: 7.0476 - val_mae: 7.0476\n",
      "Epoch 263/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5259 - mae: 9.5259 - val_loss: 7.0435 - val_mae: 7.0435\n",
      "Epoch 264/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.9239 - mae: 10.9239 - val_loss: 6.9973 - val_mae: 6.9973\n",
      "Epoch 265/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.7780 - mae: 9.7780 - val_loss: 6.9326 - val_mae: 6.9326\n",
      "Epoch 266/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.0524 - mae: 10.0524 - val_loss: 6.8997 - val_mae: 6.8997\n",
      "Epoch 267/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.9307 - mae: 10.9307 - val_loss: 6.9312 - val_mae: 6.9312\n",
      "Epoch 268/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.1937 - mae: 10.1937 - val_loss: 6.9591 - val_mae: 6.9591\n",
      "Epoch 269/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.4623 - mae: 10.4623 - val_loss: 6.8850 - val_mae: 6.8850\n",
      "Epoch 270/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.2160 - mae: 10.2160 - val_loss: 6.8256 - val_mae: 6.8256\n",
      "Epoch 271/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.7351 - mae: 10.7351 - val_loss: 6.8050 - val_mae: 6.8050\n",
      "Epoch 272/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.7601 - mae: 10.7601 - val_loss: 6.7577 - val_mae: 6.7577\n",
      "Epoch 273/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5199 - mae: 9.5199 - val_loss: 6.7280 - val_mae: 6.7280\n",
      "Epoch 274/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.0047 - mae: 11.0047 - val_loss: 6.7429 - val_mae: 6.7429\n",
      "Epoch 275/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5652 - mae: 9.5652 - val_loss: 6.7508 - val_mae: 6.7508\n",
      "Epoch 276/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.8269 - mae: 10.8269 - val_loss: 6.8048 - val_mae: 6.8048\n",
      "Epoch 277/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.7795 - mae: 9.7795 - val_loss: 6.8343 - val_mae: 6.8343\n",
      "Epoch 278/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.3702 - mae: 10.3702 - val_loss: 6.8710 - val_mae: 6.8710\n",
      "Epoch 279/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.8599 - mae: 9.8599 - val_loss: 6.8428 - val_mae: 6.8428\n",
      "Epoch 280/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.2355 - mae: 10.2355 - val_loss: 6.8417 - val_mae: 6.8417\n",
      "Epoch 281/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.4932 - mae: 10.4932 - val_loss: 6.8583 - val_mae: 6.8583\n",
      "Epoch 282/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.1710 - mae: 10.1710 - val_loss: 6.7812 - val_mae: 6.7812\n",
      "Epoch 283/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.0914 - mae: 10.0914 - val_loss: 6.7291 - val_mae: 6.7291\n",
      "Epoch 284/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.9103 - mae: 9.9103 - val_loss: 6.7143 - val_mae: 6.7143\n",
      "Epoch 285/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.5479 - mae: 10.5479 - val_loss: 6.7111 - val_mae: 6.7111\n",
      "Epoch 286/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.5662 - mae: 9.5662 - val_loss: 6.7309 - val_mae: 6.7309\n",
      "Epoch 287/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.7684 - mae: 9.7684 - val_loss: 6.8141 - val_mae: 6.8141\n",
      "Epoch 288/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.2277 - mae: 10.2277 - val_loss: 6.8563 - val_mae: 6.8563\n",
      "Epoch 289/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.2026 - mae: 10.2026 - val_loss: 6.8698 - val_mae: 6.8698\n",
      "Epoch 290/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.6845 - mae: 10.6845 - val_loss: 6.8937 - val_mae: 6.8937\n",
      "Epoch 291/2000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.0730 - mae: 10.0730 - val_loss: 6.9113 - val_mae: 6.9113\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_25\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_25\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_97 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">608</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_98 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_97 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m608\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_98 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_99 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_100 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> (15.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,845\u001b[0m (15.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,281</span> (5.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,281\u001b[0m (5.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,564</span> (10.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,564\u001b[0m (10.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4.97659158706665\n",
      "\n",
      "테스트 데이터에 대한 최종 Mean Absolute Error (MAE): 4.98분\n",
      "-> 모델의 예측치가 실제값과 평균적으로 4.98분 정도 차이남을 의미합니다.\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "--- 실제 시간과 예측 시간 비교 (상위 5개) ---\n",
      "   실제 시간      예측 시간        차이\n",
      "0     36  34.336887  1.663113\n",
      "1     27  27.064228 -0.064228\n",
      "2     49  45.166656  3.833344\n",
      "3     89  84.603966  4.396034\n",
      "4     54  51.095783  2.904217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minux/miniforge3/envs/jupyter_env/lib/python3.11/site-packages/sklearn/pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "df = pd.read_csv('~/Food_Delivery_Times.csv')\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "X = df.drop(['Order_ID', 'Delivery_Time_min'], axis='columns')\n",
    "y = df['Delivery_Time_min']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"훈련 데이터 수: {len(X_train)}개, 테스트 데이터 수: {len(X_test)}개\")\n",
    "\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('Traffic_Level', categorical_transformer, ['Traffic_Level']),\n",
    "        ('Time_of_Day', categorical_transformer, ['Time_of_Day']),\n",
    "        ('Vehicle_Type', categorical_transformer, ['Vehicle_Type']),\n",
    "        ('Weather', categorical_transformer, ['Weather']),\n",
    "        ('Distance_km', numeric_transformer, ['Distance_km']),\n",
    "        ('Preparation', numeric_transformer, ['Preparation_Time_min']),\n",
    "        ('Courier', numeric_transformer, ['Courier_Experience_yrs']),\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32, activation='linear'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation='linear'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(8, activation='linear'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='mean_absolute_error', metrics=['mae'])\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', model)])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=40, restore_best_weights=True)\n",
    "\n",
    "history = pipeline.fit(X_train, y_train,\n",
    "                       regressor__epochs=2000,\n",
    "                       regressor__batch_size=64,\n",
    "                       regressor__validation_split=0.1,\n",
    "                       regressor__callbacks=[early_stopping],\n",
    "                       regressor__verbose=1)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Preprocess X_test before evaluating the model\n",
    "X_test_processed = pipeline.named_steps['preprocessor'].transform(X_test)\n",
    "\n",
    "loss, mae = model.evaluate(X_test_processed, y_test, verbose=0)\n",
    "print(f\"\\n{loss}\")\n",
    "print(f\"\\n테스트 데이터에 대한 최종 Mean Absolute Error (MAE): {mae:,.2f}분\")\n",
    "print(f\"-> 모델의 예측치가 실제값과 평균적으로 {mae:,.2f}분 정도 차이남을 의미합니다.\")\n",
    "\n",
    "\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    '실제 시간': y_test.values.flatten(),\n",
    "    '예측 시간': predictions.flatten()\n",
    "})\n",
    "results_df['차이'] = results_df['실제 시간'] - results_df['예측 시간']\n",
    "\n",
    "print(\"\\n--- 실제 시간과 예측 시간 비교 (상위 5개) ---\")\n",
    "print(results_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934dbf0d-cba8-42ba-8a6d-e1147435808e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b21bc80-9a5a-44a2-b73d-3cd7817f6075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
